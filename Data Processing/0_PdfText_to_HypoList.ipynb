{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "def dotToUnder(pat_obj):\n",
    "    pattern = pat_obj.group(0)\n",
    "    return pattern.replace(\".\", \"_\")\n",
    "def text_name_sort(text_name):\n",
    "    return int(text_name.split(\".txt\")[0])\n",
    "\n",
    "pat_g1 = \"Hypothesis *\\d[a-zA-Z]*|hypothesis *\\d[a-zA-Z]*\"\n",
    "pat_g2 = \"|(?:^|[^a-zA-Z])H *\\d[a-zA-Z]*|(?:^|[^a-zA-Z])h *\\d[a-zA-Z]*\"\n",
    "pat_g3 = \"|(?:^|[^a-zA-Z])H[a-zA-Z]:|(?:^|[^a-zA-Z])h[a-zA-Z]:\"\n",
    "pat_g4 = \"|(?:^|[^a-zA-Z])H...:|(?:^|[^a-zA-Z])H..:|(?:^|[^a-zA-Z])H.:|(?:^|[^a-zA-Z])H:\"\n",
    "pat_g5 = \"|(?:^|[^a-zA-Z])H...,|(?:^|[^a-zA-Z])H..,|(?:^|[^a-zA-Z])H.,\"\n",
    "pat_g6 = \"|(?:^|[^a-zA-Z])\\(H...\\)|(?:^|[^a-zA-Z])\\(H..\\)|(?:^|[^a-zA-Z])\\(H.\\)\"\n",
    "pat_g7 = \"|(?:^|[^a-zA-Z])H...\\_|(?:^|[^a-zA-Z])H..\\_|(?:^|[^a-zA-Z])H.\\_\"\n",
    "pat_g8 = \"|(?:^|[^a-zA-Z])H.. |(?:^|[^a-zA-Z])H. \"\n",
    "\n",
    "h_pattern = pat_g1 + pat_g2 + pat_g3 + pat_g4 + pat_g5 + pat_g6 + pat_g7 + pat_g8\n",
    "#test result patterns\n",
    "test_pattern = \"(true|not significant|support|reject|disconfirm|confirm|accept|not |consistent |\\*+p)\"\n",
    "\n",
    "input_path = \"../Data/Pdf Texts/\"\n",
    "text_list = []\n",
    "pdf_list  = []\n",
    "text_name_list = os.listdir(input_path)\n",
    "text_name_list.sort(key = text_name_sort)\n",
    "\n",
    "for t_pdf_seq, text_name in enumerate(text_name_list):\n",
    "    if t_pdf_seq % 1000 == 0:\n",
    "        print(t_pdf_seq)\n",
    "        \n",
    "    file = open(input_path+text_name, \"r\", encoding = \"UTF-8\")\n",
    "    texture = \"\"\n",
    "    for line in file:\n",
    "        texture += line\n",
    "\n",
    "    t_text_new = texture\n",
    "    sen_list = t_text_new.split(\"\\n\")\n",
    "    new_text = \" \".join(sen_list)\n",
    "    new_text = re.sub(\"Fig\\.|\\d\\.|\\d[a-z]\\.|e\\.g\\.|i\\.e\\.|al\\.|\\d \\.|U\\.S\\.|etc\\.|p \\< \\.|H.\\.|H..\\.|H...\\.\",dotToUnder, new_text)\n",
    "    sen_list2 = re.split(\"\\.|\\?|\\!\", new_text)#\\. [A-Z]\n",
    "    \n",
    "    t_h_sen_objs = []\n",
    "    for sen in sen_list2:\n",
    "        searchObj = re.search(h_pattern, sen)\n",
    "        if searchObj:\n",
    "            t_dict = {}\n",
    "            t_dict[\"h_sen\"] = sen\n",
    "            t_dict[\"type\"] = -1\n",
    "            t_dict[\"type_seq\"] = -1\n",
    "            t_dict[\"complete\"] = \"noStart\"\n",
    "            t_dict[\"pattern\"] = searchObj.group(0)\n",
    "            t_h_sen_objs.append(t_dict)\n",
    "    if len(t_h_sen_objs) > 0:\n",
    "        pdf_obj = {}\n",
    "        pdf_obj[\"seq_all\"] = int(text_name.split(\".txt\")[0])\n",
    "        pdf_obj[\"seq\"] = t_pdf_seq\n",
    "        pdf_obj[\"complete\"] = \"noStart\"\n",
    "        \n",
    "        pdf_obj[\"h_extract_obj\"] = {}\n",
    "        pdf_obj[\"h_extract_obj\"][\"h_sen_objs\"] = t_h_sen_objs\n",
    "        pdf_obj[\"h_extract_obj\"][\"hypo_sen_objs\"] = []\n",
    "        pdf_obj[\"h_extract_obj\"][\"resu_sen_objs\"] = []\n",
    "        pdf_obj[\"h_extract_obj\"][\"invalid_sen_objs\"] = []\n",
    "        \n",
    "        pdf_list.append(pdf_obj)\n",
    "    \n",
    "        text_list.append(texture)\n",
    "\n",
    "#Output\n",
    "file = open(\"../Data/data.json\", \"w\")\n",
    "json.dump(pdf_list, file)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
