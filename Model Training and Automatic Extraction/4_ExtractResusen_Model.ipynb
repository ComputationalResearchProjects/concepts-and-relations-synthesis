{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5zWC8b97IFw"
   },
   "source": [
    "Download Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 54543,
     "status": "ok",
     "timestamp": 1662525846629,
     "user": {
      "displayName": "兰吉",
      "userId": "03033242916130806806"
     },
     "user_tz": -480
    },
    "id": "NnKJe4coe5u1",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "ef26ac75-1cb3-404c-f7fe-ba68d17eb3fe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'transformers'...\n",
      "remote: Enumerating objects: 98996, done.\u001b[K\n",
      "remote: Total 98996 (delta 0), reused 0 (delta 0), pack-reused 98996\u001b[K\n",
      "Receiving objects: 100% (98996/98996), 95.25 MiB | 30.28 MiB/s, done.\n",
      "Resolving deltas: 100% (73466/73466), done.\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-04d2r69h\n",
      "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-04d2r69h\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (2.23.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (21.3)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 7.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (4.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (1.21.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (2022.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (4.64.0)\n",
      "Collecting huggingface-hub<1.0,>=0.9.0\n",
      "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
      "\u001b[K     |████████████████████████████████| 120 kB 75.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.22.0.dev0) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers==4.22.0.dev0) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.22.0.dev0) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.22.0.dev0) (3.8.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.22.0.dev0) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.22.0.dev0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.22.0.dev0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.22.0.dev0) (1.24.3)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for transformers: filename=transformers-4.22.0.dev0-py3-none-any.whl size=4792413 sha256=c347d439e6a9288b3238aa6fc0725c66d2bcbd38b4a91c065f922627e59b4bf0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9cc2mift/wheels/35/2e/a7/d819e3310040329f0f47e57c9e3e7a7338aa5e74c49acfe522\n",
      "Successfully built transformers\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.22.0.dev0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
      "\u001b[K     |████████████████████████████████| 365 kB 7.2 MB/s \n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 74.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[K     |████████████████████████████████| 212 kB 70.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.1)\n",
      "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 53.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "Successfully installed datasets-2.4.0 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.2.2-py3-none-any.whl (69 kB)\n",
      "\u001b[K     |████████████████████████████████| 69 kB 4.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (2022.8.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from evaluate) (4.64.0)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from evaluate) (1.21.6)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.9.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from evaluate) (4.12.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.70.13)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from evaluate) (1.3.5)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from evaluate) (3.0.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.3.5.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (2.4.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (2.23.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->evaluate) (3.8.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.1.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->evaluate) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->evaluate) (3.8.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->evaluate) (2022.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.2.2\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.22.0.dev0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting jsonlines\n",
      "  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonlines) (4.1.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from jsonlines) (22.1.0)\n",
      "Installing collected packages: jsonlines\n",
      "Successfully installed jsonlines-3.1.0\n"
     ]
    }
   ],
   "source": [
    "#Download Code\n",
    "!rm -rf transformers\n",
    "!git clone https://github.com/ComputationalResearchProjects/transformers\n",
    "!pip install git+https://github.com/huggingface/transformers\n",
    "!pip install datasets\n",
    "!pip install evaluate\n",
    "!pip install transformers\n",
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXAtC88U7IFz"
   },
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ZuyLlK73nHT"
   },
   "outputs": [],
   "source": [
    "# generate train, test, dev.csv\n",
    "import json\n",
    "import pandas as pd\n",
    "#Upload bert_textClass.py\n",
    "import bert_textClass as f\n",
    "import imp\n",
    "imp.reload(f)\n",
    "\n",
    "# !mkdir data\n",
    "#Upload resu_sen_dict.json to data/\n",
    "!mkdir output\n",
    "\n",
    "resu_sen_dict = f.read_json(\"data/resu_sen_dict.json\")\n",
    "dataset = f.split(resu_sen_dict)\n",
    "f.write_files(dataset, \"data/\")\n",
    "\n",
    "\n",
    "!python /content/transformers/examples/pytorch/text-classification/run_glue.py \\\n",
    "    --model_name_or_path bert-base-cased \\\n",
    "    --train_file data/train.json \\\n",
    "    --validation_file data/dev.json \\\n",
    "    --test_file data/test.json \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_predict \\\n",
    "    --save_steps 30000 \\\n",
    "    --max_seq_length 128 \\\n",
    "    --per_device_train_batch_size 32 \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --num_train_epochs 15 \\\n",
    "    --output_dir output \\\n",
    "    --overwrite_output_dir True\n",
    "\n",
    "!cp -r ./output/predict_results_None.txt ./output/4.2_test_predictions.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmBEactT7IFz"
   },
   "source": [
    "Compute Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "executionInfo": {
     "elapsed": 5069,
     "status": "ok",
     "timestamp": 1597575926792,
     "user": {
      "displayName": "兰吉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjvj34bfxli1mhfSYfY7FjsuI4i8-rZUFwYhdoC=s64",
      "userId": "03033242916130806806"
     },
     "user_tz": -480
    },
    "id": "rzwZXuhEBb_6",
    "outputId": "82d79ad4-6844-4ee9-b863-f3c26c5bb035"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       517\n",
      "           1       0.90      0.88      0.89       100\n",
      "\n",
      "    accuracy                           0.96       617\n",
      "   macro avg       0.94      0.93      0.93       617\n",
      "weighted avg       0.96      0.96      0.96       617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tf1 = pd.read_csv(\"data/test.tsv\", sep = \"\\t\")\n",
    "y_test = tf1[\"label\"].values.tolist()\n",
    "\n",
    "file = open(\"output/4.2train_test_predictions.txt\", \"r\")\n",
    "y_pred = []\n",
    "file.readline()\n",
    "for line in file:\n",
    "    t_label = int(line.strip(\"\\n\").split(\"\\t\")[1])\n",
    "    y_pred.append(t_label)\n",
    "file.close()\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNRgIfLP7IF0"
   },
   "source": [
    "Use Model to Extract Info Automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 946183,
     "status": "ok",
     "timestamp": 1662527057023,
     "user": {
      "displayName": "兰吉",
      "userId": "03033242916130806806"
     },
     "user_tz": -480
    },
    "id": "xE2cOF-Z7IF0",
    "outputId": "46540cf4-4f36-4c5a-97e0-06beb12e3818"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "INFO:__main__:Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=True,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=output/runs/Sep07_04-48-37_359302bbece4,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=15.0,\n",
      "optim=adamw_hf,\n",
      "output_dir=output,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=output,\n",
      "save_on_each_node=False,\n",
      "save_steps=30000,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "INFO:__main__:load a local file for train: data/train.json\n",
      "INFO:__main__:load a local file for validation: data/dev.json\n",
      "INFO:__main__:load a local file for test: data/test.json\n",
      "WARNING:datasets.builder:Using custom data configuration default-2ce7ef7b0620cb30\n",
      "INFO:datasets.builder:Generating dataset json (/root/.cache/huggingface/datasets/json/default-2ce7ef7b0620cb30/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
      "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-2ce7ef7b0620cb30/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253...\n",
      "Downloading data files: 100% 3/3 [00:00<00:00, 10188.59it/s]\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Extracting data files: 100% 3/3 [00:00<00:00, 1033.67it/s]\n",
      "INFO:datasets.utils.info_utils:Unable to verify checksums.\n",
      "INFO:datasets.builder:Generating train split\n",
      "INFO:datasets.builder:Generating validation split\n",
      "INFO:datasets.builder:Generating test split\n",
      "INFO:datasets.utils.info_utils:Unable to verify splits sizes.\n",
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-2ce7ef7b0620cb30/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253. Subsequent calls will reuse this data.\n",
      "100% 3/3 [00:00<00:00, 703.90it/s]\n",
      "Downloading: 100% 570/570 [00:00<00:00, 353kB/s]\n",
      "[INFO|configuration_utils.py:643] 2022-09-07 04:48:38,709 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/a8d257ba9925ef39f3036bfc338acf5283c512d9/config.json\n",
      "[INFO|configuration_utils.py:695] 2022-09-07 04:48:38,723 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "Downloading: 100% 29.0/29.0 [00:00<00:00, 19.0kB/s]\n",
      "[INFO|configuration_utils.py:643] 2022-09-07 04:48:39,330 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/a8d257ba9925ef39f3036bfc338acf5283c512d9/config.json\n",
      "[INFO|configuration_utils.py:695] 2022-09-07 04:48:39,331 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "Downloading: 100% 213k/213k [00:00<00:00, 1.15MB/s]\n",
      "Downloading: 100% 436k/436k [00:00<00:00, 1.41MB/s]\n",
      "[INFO|tokenization_utils_base.py:1766] 2022-09-07 04:48:41,555 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/a8d257ba9925ef39f3036bfc338acf5283c512d9/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:1766] 2022-09-07 04:48:41,555 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/a8d257ba9925ef39f3036bfc338acf5283c512d9/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1766] 2022-09-07 04:48:41,555 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1766] 2022-09-07 04:48:41,555 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1766] 2022-09-07 04:48:41,556 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/a8d257ba9925ef39f3036bfc338acf5283c512d9/tokenizer_config.json\n",
      "[INFO|configuration_utils.py:643] 2022-09-07 04:48:41,556 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/a8d257ba9925ef39f3036bfc338acf5283c512d9/config.json\n",
      "[INFO|configuration_utils.py:695] 2022-09-07 04:48:41,557 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "Downloading: 100% 436M/436M [00:06<00:00, 72.1MB/s]\n",
      "[INFO|modeling_utils.py:2071] 2022-09-07 04:48:47,992 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/a8d257ba9925ef39f3036bfc338acf5283c512d9/pytorch_model.bin\n",
      "[WARNING|modeling_utils.py:2501] 2022-09-07 04:48:49,404 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:2513] 2022-09-07 04:48:49,404 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Running tokenizer on dataset:   0% 0/5 [00:00<?, ?ba/s]INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-2ce7ef7b0620cb30/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-06eb57557f038853.arrow\n",
      "Running tokenizer on dataset: 100% 5/5 [00:00<00:00,  8.66ba/s]\n",
      "Running tokenizer on dataset:   0% 0/2 [00:00<?, ?ba/s]INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-2ce7ef7b0620cb30/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-2a0d2f2811bcc7d7.arrow\n",
      "Running tokenizer on dataset: 100% 2/2 [00:00<00:00, 13.94ba/s]\n",
      "Running tokenizer on dataset:   0% 0/8 [00:00<?, ?ba/s]INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-2ce7ef7b0620cb30/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-09fab7b52176c131.arrow\n",
      "Running tokenizer on dataset: 100% 8/8 [00:01<00:00,  7.44ba/s]\n",
      "INFO:__main__:Sample 912 of the training set: {'sentence': '  BYNES  4_ Social Cohesion  How much do you agree with the statements below . ', 'label': 0, 'input_ids': [101, 139, 3663, 22680, 1708, 125, 168, 3563, 3291, 23746, 1731, 1277, 1202, 1128, 5340, 1114, 1103, 8477, 2071, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "INFO:__main__:Sample 204 of the training set: {'sentence': '  Our results supported H1, which proposed a positive relationship between the number of people a user follows and the user’s in-degree links (B=-— . ', 'label': 1, 'input_ids': [101, 3458, 2686, 2726, 145, 1475, 117, 1134, 3000, 170, 3112, 2398, 1206, 1103, 1295, 1104, 1234, 170, 4795, 3226, 1105, 1103, 4795, 787, 188, 1107, 118, 2178, 6743, 113, 139, 134, 118, 783, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "INFO:__main__:Sample 2253 of the training set: {'sentence': ' New York: McGraw-Hill_  Freeman JR (1983) Granger causality and the times series analysis of political relationships . ', 'label': 0, 'input_ids': [101, 1203, 1365, 131, 27315, 118, 2404, 168, 11818, 16572, 113, 2278, 114, 20281, 1197, 11019, 25034, 1785, 1105, 1103, 1551, 1326, 3622, 1104, 1741, 6085, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "Downloading builder script: 100% 4.20k/4.20k [00:00<00:00, 3.54MB/s]\n",
      "[INFO|trainer.py:745] 2022-09-07 04:48:58,841 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence. If sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "[INFO|trainer.py:1627] 2022-09-07 04:48:58,857 >> ***** Running training *****\n",
      "[INFO|trainer.py:1628] 2022-09-07 04:48:58,858 >>   Num examples = 4931\n",
      "[INFO|trainer.py:1629] 2022-09-07 04:48:58,858 >>   Num Epochs = 15\n",
      "[INFO|trainer.py:1630] 2022-09-07 04:48:58,858 >>   Instantaneous batch size per device = 32\n",
      "[INFO|trainer.py:1631] 2022-09-07 04:48:58,858 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:1632] 2022-09-07 04:48:58,858 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1633] 2022-09-07 04:48:58,858 >>   Total optimization steps = 2325\n",
      "{'loss': 0.1112, 'learning_rate': 1.5698924731182796e-05, 'epoch': 3.23}\n",
      "{'loss': 0.0254, 'learning_rate': 1.1397849462365593e-05, 'epoch': 6.45}\n",
      "{'loss': 0.0076, 'learning_rate': 7.096774193548388e-06, 'epoch': 9.68}\n",
      "{'loss': 0.0019, 'learning_rate': 2.7956989247311827e-06, 'epoch': 12.9}\n",
      "100% 2324/2325 [14:32<00:00,  2.67it/s][INFO|trainer.py:1872] 2022-09-07 05:03:31,637 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 872.7817, 'train_samples_per_second': 84.746, 'train_steps_per_second': 2.664, 'train_loss': 0.03146437366162577, 'epoch': 15.0}\n",
      "100% 2325/2325 [14:32<00:00,  2.66it/s]\n",
      "[INFO|trainer.py:2668] 2022-09-07 05:03:31,641 >> Saving model checkpoint to output\n",
      "[INFO|configuration_utils.py:440] 2022-09-07 05:03:31,642 >> Configuration saved in output/config.json\n",
      "[INFO|modeling_utils.py:1573] 2022-09-07 05:03:33,466 >> Model weights saved in output/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2116] 2022-09-07 05:03:33,467 >> tokenizer config file saved in output/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2123] 2022-09-07 05:03:33,467 >> Special tokens file saved in output/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =       15.0\n",
      "  train_loss               =     0.0315\n",
      "  train_runtime            = 0:14:32.78\n",
      "  train_samples            =       4931\n",
      "  train_samples_per_second =     84.746\n",
      "  train_steps_per_second   =      2.664\n",
      "INFO:__main__:*** Evaluate ***\n",
      "[INFO|trainer.py:745] 2022-09-07 05:03:33,502 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence. If sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:2919] 2022-09-07 05:03:33,504 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2921] 2022-09-07 05:03:33,504 >>   Num examples = 1233\n",
      "[INFO|trainer.py:2924] 2022-09-07 05:03:33,504 >>   Batch size = 8\n",
      "100% 155/155 [00:05<00:00, 28.43it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =       15.0\n",
      "  eval_accuracy           =     0.9684\n",
      "  eval_loss               =     0.2276\n",
      "  eval_runtime            = 0:00:05.57\n",
      "  eval_samples            =       1233\n",
      "  eval_samples_per_second =    221.012\n",
      "  eval_steps_per_second   =     27.783\n",
      "INFO:__main__:*** Predict ***\n",
      "[INFO|trainer.py:745] 2022-09-07 05:03:39,087 >> The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence. If sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:2919] 2022-09-07 05:03:39,088 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2921] 2022-09-07 05:03:39,088 >>   Num examples = 7921\n",
      "[INFO|trainer.py:2924] 2022-09-07 05:03:39,088 >>   Batch size = 8\n",
      "100% 991/991 [00:34<00:00, 29.14it/s]\n",
      "INFO:__main__:***** Predict results None *****\n",
      "[INFO|modelcard.py:443] 2022-09-07 05:04:13,444 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.9683698415756226}]}\n",
      "cp: cannot stat './output/test_results_sst-2.txt': No such file or directory\n",
      "cp: cannot stat './output/4.2_test_predictions.txt': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "imp.reload(f)\n",
    "!rm -rf output\n",
    "!mkdir output\n",
    "\n",
    "#Upload resu_sen_pred_dict.json to data/\n",
    "resu_sen_dict = f.read_json(\"data/resu_sen_dict.json\")\n",
    "resu_sen_pred_dict = f.read_json(\"data/resu_sen_pred_dict.json\")\n",
    "dataset = f.geneTrainEvaTest(resu_sen_dict, resu_sen_pred_dict)\n",
    "f.write_files(dataset, \"data/\")\n",
    "\n",
    "!python /content/transformers/examples/pytorch/text-classification/run_glue.py \\\n",
    "    --model_name_or_path bert-base-cased \\\n",
    "    --train_file data/train.json \\\n",
    "    --validation_file data/dev.json \\\n",
    "    --test_file data/test.json \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_predict \\\n",
    "    --save_steps 30000 \\\n",
    "    --max_seq_length 128 \\\n",
    "    --per_device_train_batch_size 32 \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --num_train_epochs 15 \\\n",
    "    --output_dir output \\\n",
    "    --overwrite_output_dir True\n",
    "\n",
    "!cp -r ./output/predict_results_None.txt ./output/4.2_test_predictions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kXVjFS4S9j_"
   },
   "outputs": [],
   "source": [
    "!cp -r ./output/predict_results_None.txt ./output/4.2_test_predictions.txt\n",
    "!cp -r ./output/4.2_test_predictions.txt ./drive/MyDrive/4.2_test_predictions.txt"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
