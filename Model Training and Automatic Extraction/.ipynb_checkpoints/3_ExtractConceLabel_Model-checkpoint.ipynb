{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APADIUZQ-KXp"
   },
   "source": [
    "Download Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3087,
     "status": "ok",
     "timestamp": 1664178256845,
     "user": {
      "displayName": "兰吉",
      "userId": "03033242916130806806"
     },
     "user_tz": -480
    },
    "id": "6aoJxoQC-KXs",
    "outputId": "186c42af-5966-4141-f5c7-061ab3aed7d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'NeuralNLP-NeuralClassifier'...\n",
      "remote: Enumerating objects: 136, done.\u001b[K\n",
      "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
      "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
      "remote: Total 136 (delta 26), reused 14 (delta 14), pack-reused 90\u001b[K\n",
      "Receiving objects: 100% (136/136), 13.66 MiB | 6.34 MiB/s, done.\n",
      "Resolving deltas: 100% (57/57), done.\n"
     ]
    }
   ],
   "source": [
    "#Download Code\n",
    "import os\n",
    "path = \"/content/\"\n",
    "os.chdir(path)\n",
    "!rm -rf ../NeuralNLP-NeuralClassifier\n",
    "!git clone https://github.com/ComputationalResearchProjects/NeuralNLP-NeuralClassifier\n",
    "path = \"/content/NeuralNLP-NeuralClassifier/\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_f7Naxwk-PCq"
   },
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "LtEu4soTk102",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import networkx as nx\n",
    "random_seed = 2023\n",
    "# Upload bert_HC2.py to ./NeuralNLP-NeuralClassifier/\n",
    "import bert_HC2 as f\n",
    "import imp\n",
    "imp.reload(f)\n",
    "\n",
    "# !mkdir data\n",
    "#Upload varia_label_dict2.json to ./NeuralNLP-NeuralClassifier/data/\n",
    "!mkdir data1\n",
    "\n",
    "data_dict = f.read_json(\"data/varia_label_dict2.json\")\n",
    "train_data, dev_data, test_data, node_list = f.build_train_dev_test(data_dict, random_seed)\n",
    "\n",
    "f.write_json(train_data, \"data1/train.json\")\n",
    "f.write_json(dev_data, \"data1/dev.json\")\n",
    "f.write_json(test_data, \"data1/test.json\")\n",
    "f.write_taxonomy(node_list, \"data1/taxonomy.txt\")\n",
    "\n",
    "!python train.py conf/train_new.json\n",
    "!python predict.py conf/train_new.json data1/test.json \n",
    "!cp -r predict.txt 3_train_test_predictions2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyoCBtjV-KXt"
   },
   "source": [
    "Compute Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fsrz86K5KWR9"
   },
   "outputs": [],
   "source": [
    "import bert_HC2 as f\n",
    "import imp\n",
    "imp.reload(f)\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Input\n",
    "test_pred_label_list = []\n",
    "file = open(\"3_train_test_predictions2.txt\", \"r\")\n",
    "for line in file:\n",
    "    test_pred_label_list.append(line.strip(\"\\n\"))\n",
    "file.close()\n",
    "\n",
    "#Process\n",
    "test_label_list = []\n",
    "for item in test_data:\n",
    "    test_label_list.append(item[\"doc_label\"][0])\n",
    "var_list = []\n",
    "for item in test_data:\n",
    "    var_list.append(\" \".join(item[\"doc_token\"]))\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(test_label_list, test_pred_label_list))\n",
    "\n",
    "t_label_list = []\n",
    "for item in test_label_list:\n",
    "    if item not in t_label_list:\n",
    "        t_label_list.append(item)\n",
    "\n",
    "t_matrix = confusion_matrix(test_label_list, test_pred_label_list, labels = t_label_list)\n",
    "df = pd.DataFrame(t_matrix, columns = t_label_list, index = t_label_list)\n",
    "df.to_csv(\"temp.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xsePF---KXu"
   },
   "source": [
    "Use Model to Extract Info Automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57068,
     "status": "ok",
     "timestamp": 1664178605365,
     "user": {
      "displayName": "兰吉",
      "userId": "03033242916130806806"
     },
     "user_tz": -480
    },
    "id": "5LGhZVBZ-KXu",
    "outputId": "d547df17-1135-4a60-b2bf-6f298dfa9da8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use dataset to generate dict.\n",
      "Size of doc_label dict is 210\n",
      "Size of doc_token dict is 1778\n",
      "Size of doc_char dict is 73\n",
      "Size of doc_token_ngram dict is 0\n",
      "Size of doc_keyword dict is 0\n",
      "Size of doc_topic dict is 0\n",
      "Shrink dict over.\n",
      "Size of doc_label dict is 210\n",
      "Size of doc_token dict is 1655\n",
      "Size of doc_char dict is 72\n",
      "Size of doc_token_ngram dict is 0\n",
      "Size of doc_keyword dict is 0\n",
      "Size of doc_topic dict is 0\n",
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "Train performance at epoch 1 is precision: 0.108874, recall: 0.108874, fscore: 0.108874, macro-fscore: 0.003921, right: 146, predict: 1341, standard: 1341.\n",
      "Loss is: 0.033128.\n",
      "Validate performance at epoch 1 is precision: 0.092593, recall: 0.092593, fscore: 0.092593, macro-fscore: 0.003562, right: 15, predict: 162, standard: 162.\n",
      "Loss is: 0.031337.\n",
      "test performance at epoch 1 is precision: 0.107955, recall: 0.107955, fscore: 0.107955, macro-fscore: 0.003159, right: 19, predict: 176, standard: 176.\n",
      "Loss is: 0.031584.\n",
      "Epoch 1 cost time: 2 second\n",
      "Train performance at epoch 2 is precision: 0.160328, recall: 0.160328, fscore: 0.160328, macro-fscore: 0.011386, right: 215, predict: 1341, standard: 1341.\n",
      "Loss is: 0.059644.\n",
      "Validate performance at epoch 2 is precision: 0.135802, recall: 0.135802, fscore: 0.135802, macro-fscore: 0.003766, right: 22, predict: 162, standard: 162.\n",
      "Loss is: 0.062588.\n",
      "test performance at epoch 2 is precision: 0.170455, recall: 0.170455, fscore: 0.170455, macro-fscore: 0.007672, right: 30, predict: 176, standard: 176.\n",
      "Loss is: 0.061094.\n",
      "Epoch 2 cost time: 1 second\n",
      "Train performance at epoch 3 is precision: 0.214019, recall: 0.214019, fscore: 0.214019, macro-fscore: 0.014644, right: 287, predict: 1341, standard: 1341.\n",
      "Loss is: 0.056088.\n",
      "Validate performance at epoch 3 is precision: 0.166667, recall: 0.166667, fscore: 0.166667, macro-fscore: 0.007809, right: 27, predict: 162, standard: 162.\n",
      "Loss is: 0.060303.\n",
      "test performance at epoch 3 is precision: 0.215909, recall: 0.215909, fscore: 0.215909, macro-fscore: 0.006477, right: 38, predict: 176, standard: 176.\n",
      "Loss is: 0.055598.\n",
      "Epoch 3 cost time: 1 second\n",
      "Train performance at epoch 4 is precision: 0.305742, recall: 0.305742, fscore: 0.305742, macro-fscore: 0.043920, right: 410, predict: 1341, standard: 1341.\n",
      "Loss is: 0.057051.\n",
      "Validate performance at epoch 4 is precision: 0.290123, recall: 0.290123, fscore: 0.290123, macro-fscore: 0.035248, right: 47, predict: 162, standard: 162.\n",
      "Loss is: 0.060230.\n",
      "test performance at epoch 4 is precision: 0.295455, recall: 0.295455, fscore: 0.295455, macro-fscore: 0.022924, right: 52, predict: 176, standard: 176.\n",
      "Loss is: 0.055315.\n",
      "Epoch 4 cost time: 1 second\n",
      "Train performance at epoch 5 is precision: 0.445190, recall: 0.445190, fscore: 0.445190, macro-fscore: 0.111159, right: 597, predict: 1341, standard: 1341.\n",
      "Loss is: 0.051270.\n",
      "Validate performance at epoch 5 is precision: 0.364198, recall: 0.364198, fscore: 0.364198, macro-fscore: 0.052594, right: 59, predict: 162, standard: 162.\n",
      "Loss is: 0.055013.\n",
      "test performance at epoch 5 is precision: 0.369318, recall: 0.369318, fscore: 0.369318, macro-fscore: 0.041676, right: 65, predict: 176, standard: 176.\n",
      "Loss is: 0.051205.\n",
      "Epoch 5 cost time: 1 second\n",
      "Train performance at epoch 6 is precision: 0.574944, recall: 0.574944, fscore: 0.574944, macro-fscore: 0.207891, right: 771, predict: 1341, standard: 1341.\n",
      "Loss is: 0.046112.\n",
      "Validate performance at epoch 6 is precision: 0.462963, recall: 0.462963, fscore: 0.462963, macro-fscore: 0.088735, right: 75, predict: 162, standard: 162.\n",
      "Loss is: 0.051976.\n",
      "test performance at epoch 6 is precision: 0.494318, recall: 0.494318, fscore: 0.494318, macro-fscore: 0.079576, right: 87, predict: 176, standard: 176.\n",
      "Loss is: 0.048798.\n",
      "Epoch 6 cost time: 1 second\n",
      "Train performance at epoch 7 is precision: 0.660701, recall: 0.660701, fscore: 0.660701, macro-fscore: 0.317390, right: 886, predict: 1341, standard: 1341.\n",
      "Loss is: 0.035637.\n",
      "Validate performance at epoch 7 is precision: 0.493827, recall: 0.493827, fscore: 0.493827, macro-fscore: 0.110662, right: 80, predict: 162, standard: 162.\n",
      "Loss is: 0.042708.\n",
      "test performance at epoch 7 is precision: 0.534091, recall: 0.534091, fscore: 0.534091, macro-fscore: 0.112725, right: 94, predict: 176, standard: 176.\n",
      "Loss is: 0.038185.\n",
      "Epoch 7 cost time: 1 second\n",
      "Train performance at epoch 8 is precision: 0.761372, recall: 0.761372, fscore: 0.761372, macro-fscore: 0.452344, right: 1021, predict: 1341, standard: 1341.\n",
      "Loss is: 0.031677.\n",
      "Validate performance at epoch 8 is precision: 0.506173, recall: 0.506173, fscore: 0.506173, macro-fscore: 0.128399, right: 82, predict: 162, standard: 162.\n",
      "Loss is: 0.040070.\n",
      "test performance at epoch 8 is precision: 0.602273, recall: 0.602273, fscore: 0.602273, macro-fscore: 0.140850, right: 106, predict: 176, standard: 176.\n",
      "Loss is: 0.036128.\n",
      "Epoch 8 cost time: 1 second\n",
      "Train performance at epoch 9 is precision: 0.853095, recall: 0.853095, fscore: 0.853095, macro-fscore: 0.603092, right: 1144, predict: 1341, standard: 1341.\n",
      "Loss is: 0.024989.\n",
      "Validate performance at epoch 9 is precision: 0.574074, recall: 0.574074, fscore: 0.574074, macro-fscore: 0.152073, right: 93, predict: 162, standard: 162.\n",
      "Loss is: 0.034799.\n",
      "test performance at epoch 9 is precision: 0.664773, recall: 0.664773, fscore: 0.664773, macro-fscore: 0.164456, right: 117, predict: 176, standard: 176.\n",
      "Loss is: 0.030189.\n",
      "Epoch 9 cost time: 1 second\n",
      "Train performance at epoch 10 is precision: 0.901566, recall: 0.901566, fscore: 0.901566, macro-fscore: 0.716301, right: 1209, predict: 1341, standard: 1341.\n",
      "Loss is: 0.021690.\n",
      "Validate performance at epoch 10 is precision: 0.567901, recall: 0.567901, fscore: 0.567901, macro-fscore: 0.152209, right: 92, predict: 162, standard: 162.\n",
      "Loss is: 0.033102.\n",
      "test performance at epoch 10 is precision: 0.676136, recall: 0.676136, fscore: 0.676136, macro-fscore: 0.174624, right: 119, predict: 176, standard: 176.\n",
      "Loss is: 0.028737.\n",
      "Epoch 10 cost time: 1 second\n",
      "Train performance at epoch 11 is precision: 0.929157, recall: 0.929157, fscore: 0.929157, macro-fscore: 0.786170, right: 1246, predict: 1341, standard: 1341.\n",
      "Loss is: 0.015890.\n",
      "Validate performance at epoch 11 is precision: 0.592593, recall: 0.592593, fscore: 0.592593, macro-fscore: 0.156975, right: 96, predict: 162, standard: 162.\n",
      "Loss is: 0.027120.\n",
      "test performance at epoch 11 is precision: 0.710227, recall: 0.710227, fscore: 0.710227, macro-fscore: 0.199420, right: 125, predict: 176, standard: 176.\n",
      "Loss is: 0.023583.\n",
      "Epoch 11 cost time: 1 second\n",
      "Train performance at epoch 12 is precision: 0.940343, recall: 0.940343, fscore: 0.940343, macro-fscore: 0.819164, right: 1261, predict: 1341, standard: 1341.\n",
      "Loss is: 0.012296.\n",
      "Validate performance at epoch 12 is precision: 0.604938, recall: 0.604938, fscore: 0.604938, macro-fscore: 0.167675, right: 98, predict: 162, standard: 162.\n",
      "Loss is: 0.024046.\n",
      "test performance at epoch 12 is precision: 0.704545, recall: 0.704545, fscore: 0.704545, macro-fscore: 0.190200, right: 124, predict: 176, standard: 176.\n",
      "Loss is: 0.020198.\n",
      "Epoch 12 cost time: 1 second\n",
      "Train performance at epoch 13 is precision: 0.965697, recall: 0.965697, fscore: 0.965697, macro-fscore: 0.888979, right: 1295, predict: 1341, standard: 1341.\n",
      "Loss is: 0.011060.\n",
      "Validate performance at epoch 13 is precision: 0.611111, recall: 0.611111, fscore: 0.611111, macro-fscore: 0.179543, right: 99, predict: 162, standard: 162.\n",
      "Loss is: 0.023897.\n",
      "test performance at epoch 13 is precision: 0.715909, recall: 0.715909, fscore: 0.715909, macro-fscore: 0.191758, right: 126, predict: 176, standard: 176.\n",
      "Loss is: 0.019009.\n",
      "Epoch 13 cost time: 1 second\n",
      "Train performance at epoch 14 is precision: 0.979866, recall: 0.979866, fscore: 0.979866, macro-fscore: 0.943462, right: 1314, predict: 1341, standard: 1341.\n",
      "Loss is: 0.008860.\n",
      "Validate performance at epoch 14 is precision: 0.635802, recall: 0.635802, fscore: 0.635802, macro-fscore: 0.195025, right: 103, predict: 162, standard: 162.\n",
      "Loss is: 0.021532.\n",
      "test performance at epoch 14 is precision: 0.727273, recall: 0.727273, fscore: 0.727273, macro-fscore: 0.204107, right: 128, predict: 176, standard: 176.\n",
      "Loss is: 0.016696.\n",
      "Epoch 14 cost time: 1 second\n",
      "Train performance at epoch 15 is precision: 0.982103, recall: 0.982103, fscore: 0.982103, macro-fscore: 0.955693, right: 1317, predict: 1341, standard: 1341.\n",
      "Loss is: 0.006738.\n",
      "Validate performance at epoch 15 is precision: 0.611111, recall: 0.611111, fscore: 0.611111, macro-fscore: 0.187446, right: 99, predict: 162, standard: 162.\n",
      "Loss is: 0.018723.\n",
      "test performance at epoch 15 is precision: 0.721591, recall: 0.721591, fscore: 0.721591, macro-fscore: 0.203873, right: 127, predict: 176, standard: 176.\n",
      "Loss is: 0.014814.\n",
      "Epoch 15 cost time: 1 second\n",
      "Train performance at epoch 16 is precision: 0.981357, recall: 0.981357, fscore: 0.981357, macro-fscore: 0.953177, right: 1316, predict: 1341, standard: 1341.\n",
      "Loss is: 0.005849.\n",
      "Validate performance at epoch 16 is precision: 0.623457, recall: 0.623457, fscore: 0.623457, macro-fscore: 0.188242, right: 101, predict: 162, standard: 162.\n",
      "Loss is: 0.017659.\n",
      "test performance at epoch 16 is precision: 0.715909, recall: 0.715909, fscore: 0.715909, macro-fscore: 0.200248, right: 126, predict: 176, standard: 176.\n",
      "Loss is: 0.013982.\n",
      "Epoch 16 cost time: 1 second\n",
      "Train performance at epoch 17 is precision: 0.984340, recall: 0.984340, fscore: 0.984340, macro-fscore: 0.963964, right: 1320, predict: 1341, standard: 1341.\n",
      "Loss is: 0.005474.\n",
      "Validate performance at epoch 17 is precision: 0.623457, recall: 0.623457, fscore: 0.623457, macro-fscore: 0.197409, right: 101, predict: 162, standard: 162.\n",
      "Loss is: 0.017470.\n",
      "test performance at epoch 17 is precision: 0.732955, recall: 0.732955, fscore: 0.732955, macro-fscore: 0.208336, right: 129, predict: 176, standard: 176.\n",
      "Loss is: 0.013974.\n",
      "Epoch 17 cost time: 1 second\n",
      "Train performance at epoch 18 is precision: 0.989560, recall: 0.989560, fscore: 0.989560, macro-fscore: 0.981715, right: 1327, predict: 1341, standard: 1341.\n",
      "Loss is: 0.004955.\n",
      "Validate performance at epoch 18 is precision: 0.617284, recall: 0.617284, fscore: 0.617284, macro-fscore: 0.194048, right: 100, predict: 162, standard: 162.\n",
      "Loss is: 0.017453.\n",
      "test performance at epoch 18 is precision: 0.727273, recall: 0.727273, fscore: 0.727273, macro-fscore: 0.207829, right: 128, predict: 176, standard: 176.\n",
      "Loss is: 0.013975.\n",
      "Epoch 18 cost time: 1 second\n",
      "Train performance at epoch 19 is precision: 0.991051, recall: 0.991051, fscore: 0.991051, macro-fscore: 0.985547, right: 1329, predict: 1341, standard: 1341.\n",
      "Loss is: 0.004071.\n",
      "Validate performance at epoch 19 is precision: 0.635802, recall: 0.635802, fscore: 0.635802, macro-fscore: 0.197986, right: 103, predict: 162, standard: 162.\n",
      "Loss is: 0.016321.\n",
      "test performance at epoch 19 is precision: 0.732955, recall: 0.732955, fscore: 0.732955, macro-fscore: 0.210722, right: 129, predict: 176, standard: 176.\n",
      "Loss is: 0.013018.\n",
      "Epoch 19 cost time: 1 second\n",
      "Train performance at epoch 20 is precision: 0.991051, recall: 0.991051, fscore: 0.991051, macro-fscore: 0.985539, right: 1329, predict: 1341, standard: 1341.\n",
      "Loss is: 0.003520.\n",
      "Validate performance at epoch 20 is precision: 0.660494, recall: 0.660494, fscore: 0.660494, macro-fscore: 0.211777, right: 107, predict: 162, standard: 162.\n",
      "Loss is: 0.015391.\n",
      "test performance at epoch 20 is precision: 0.727273, recall: 0.727273, fscore: 0.727273, macro-fscore: 0.208228, right: 128, predict: 176, standard: 176.\n",
      "Loss is: 0.012264.\n",
      "Epoch 20 cost time: 1 second\n",
      "Train performance at epoch 21 is precision: 0.991051, recall: 0.991051, fscore: 0.991051, macro-fscore: 0.988867, right: 1329, predict: 1341, standard: 1341.\n",
      "Loss is: 0.003653.\n",
      "Validate performance at epoch 21 is precision: 0.654321, recall: 0.654321, fscore: 0.654321, macro-fscore: 0.215775, right: 106, predict: 162, standard: 162.\n",
      "Loss is: 0.015832.\n",
      "test performance at epoch 21 is precision: 0.732955, recall: 0.732955, fscore: 0.732955, macro-fscore: 0.211820, right: 129, predict: 176, standard: 176.\n",
      "Loss is: 0.012386.\n",
      "Epoch 21 cost time: 1 second\n",
      "Train performance at epoch 22 is precision: 0.990306, recall: 0.990306, fscore: 0.990306, macro-fscore: 0.987980, right: 1328, predict: 1341, standard: 1341.\n",
      "Loss is: 0.003256.\n",
      "Validate performance at epoch 22 is precision: 0.648148, recall: 0.648148, fscore: 0.648148, macro-fscore: 0.209977, right: 105, predict: 162, standard: 162.\n",
      "Loss is: 0.015517.\n",
      "test performance at epoch 22 is precision: 0.727273, recall: 0.727273, fscore: 0.727273, macro-fscore: 0.206936, right: 128, predict: 176, standard: 176.\n",
      "Loss is: 0.012114.\n",
      "Epoch 22 cost time: 1 second\n",
      "Train performance at epoch 23 is precision: 0.991797, recall: 0.991797, fscore: 0.991797, macro-fscore: 0.985894, right: 1330, predict: 1341, standard: 1341.\n",
      "Loss is: 0.002948.\n",
      "Validate performance at epoch 23 is precision: 0.654321, recall: 0.654321, fscore: 0.654321, macro-fscore: 0.212873, right: 106, predict: 162, standard: 162.\n",
      "Loss is: 0.015019.\n",
      "test performance at epoch 23 is precision: 0.738636, recall: 0.738636, fscore: 0.738636, macro-fscore: 0.213101, right: 130, predict: 176, standard: 176.\n",
      "Loss is: 0.011770.\n",
      "Epoch 23 cost time: 1 second\n",
      "Train performance at epoch 24 is precision: 0.990306, recall: 0.990306, fscore: 0.990306, macro-fscore: 0.985645, right: 1328, predict: 1341, standard: 1341.\n",
      "Loss is: 0.002799.\n",
      "Validate performance at epoch 24 is precision: 0.648148, recall: 0.648148, fscore: 0.648148, macro-fscore: 0.209937, right: 105, predict: 162, standard: 162.\n",
      "Loss is: 0.014926.\n",
      "test performance at epoch 24 is precision: 0.738636, recall: 0.738636, fscore: 0.738636, macro-fscore: 0.217861, right: 130, predict: 176, standard: 176.\n",
      "Loss is: 0.011686.\n",
      "Epoch 24 cost time: 1 second\n",
      "Train performance at epoch 25 is precision: 0.990306, recall: 0.990306, fscore: 0.990306, macro-fscore: 0.988919, right: 1328, predict: 1341, standard: 1341.\n",
      "Loss is: 0.002793.\n",
      "Validate performance at epoch 25 is precision: 0.629630, recall: 0.629630, fscore: 0.629630, macro-fscore: 0.194805, right: 102, predict: 162, standard: 162.\n",
      "Loss is: 0.014773.\n",
      "test performance at epoch 25 is precision: 0.721591, recall: 0.721591, fscore: 0.721591, macro-fscore: 0.208828, right: 127, predict: 176, standard: 176.\n",
      "Loss is: 0.011735.\n",
      "Epoch 25 cost time: 1 second\n",
      "Train performance at epoch 26 is precision: 0.991051, recall: 0.991051, fscore: 0.991051, macro-fscore: 0.985755, right: 1329, predict: 1341, standard: 1341.\n",
      "Loss is: 0.002457.\n",
      "Validate performance at epoch 26 is precision: 0.648148, recall: 0.648148, fscore: 0.648148, macro-fscore: 0.201796, right: 105, predict: 162, standard: 162.\n",
      "Loss is: 0.014834.\n",
      "test performance at epoch 26 is precision: 0.727273, recall: 0.727273, fscore: 0.727273, macro-fscore: 0.209977, right: 128, predict: 176, standard: 176.\n",
      "Loss is: 0.011452.\n",
      "Epoch 26 cost time: 1 second\n",
      "Train performance at epoch 27 is precision: 0.991051, recall: 0.991051, fscore: 0.991051, macro-fscore: 0.985100, right: 1329, predict: 1341, standard: 1341.\n",
      "Loss is: 0.002529.\n",
      "Validate performance at epoch 27 is precision: 0.629630, recall: 0.629630, fscore: 0.629630, macro-fscore: 0.202606, right: 102, predict: 162, standard: 162.\n",
      "Loss is: 0.014714.\n",
      "test performance at epoch 27 is precision: 0.721591, recall: 0.721591, fscore: 0.721591, macro-fscore: 0.208570, right: 127, predict: 176, standard: 176.\n",
      "Loss is: 0.011527.\n",
      "Epoch 27 cost time: 1 second\n",
      "Train performance at epoch 28 is precision: 0.991051, recall: 0.991051, fscore: 0.991051, macro-fscore: 0.988670, right: 1329, predict: 1341, standard: 1341.\n",
      "Loss is: 0.002276.\n",
      "Validate performance at epoch 28 is precision: 0.648148, recall: 0.648148, fscore: 0.648148, macro-fscore: 0.207125, right: 105, predict: 162, standard: 162.\n",
      "Loss is: 0.014376.\n",
      "test performance at epoch 28 is precision: 0.738636, recall: 0.738636, fscore: 0.738636, macro-fscore: 0.216610, right: 130, predict: 176, standard: 176.\n",
      "Loss is: 0.011282.\n",
      "Epoch 28 cost time: 1 second\n",
      "Train performance at epoch 29 is precision: 0.988069, recall: 0.988069, fscore: 0.988069, macro-fscore: 0.982758, right: 1325, predict: 1341, standard: 1341.\n",
      "Loss is: 0.002129.\n",
      "Validate performance at epoch 29 is precision: 0.641975, recall: 0.641975, fscore: 0.641975, macro-fscore: 0.198074, right: 104, predict: 162, standard: 162.\n",
      "Loss is: 0.014344.\n",
      "test performance at epoch 29 is precision: 0.721591, recall: 0.721591, fscore: 0.721591, macro-fscore: 0.206335, right: 127, predict: 176, standard: 176.\n",
      "Loss is: 0.011347.\n",
      "Epoch 29 cost time: 1 second\n",
      "Train performance at epoch 30 is precision: 0.990306, recall: 0.990306, fscore: 0.990306, macro-fscore: 0.988564, right: 1328, predict: 1341, standard: 1341.\n",
      "Loss is: 0.002305.\n",
      "Validate performance at epoch 30 is precision: 0.654321, recall: 0.654321, fscore: 0.654321, macro-fscore: 0.207070, right: 106, predict: 162, standard: 162.\n",
      "Loss is: 0.014615.\n",
      "test performance at epoch 30 is precision: 0.727273, recall: 0.727273, fscore: 0.727273, macro-fscore: 0.209509, right: 128, predict: 176, standard: 176.\n",
      "Loss is: 0.011617.\n",
      "Epoch 30 cost time: 1 second\n",
      "Best test performance at epoch 20 is precision: 0.727273, recall: 0.727273, fscore: 0.727273, macro-fscore: 0.208228, right: 128, predict: 176, standard: 176.\n",
      "Loss is: 0.012264.\n"
     ]
    }
   ],
   "source": [
    "imp.reload(f)\n",
    "data_pred_dict = f.read_json(\"data/varia_label_pred_dict.json\")\n",
    "test_data2 = f.build_test_pred(data_pred_dict)\n",
    "f.write_json(test_data2, \"data1/test2.json\")\n",
    "\n",
    "!python train.py conf/train_new.json\n",
    "!python predict.py conf/train_new.json data1/test2.json \n",
    "!cp -r predict.txt 3_test_predictions2.txt\n",
    "!cp -r predict_pro.txt 3_predict_pro.txt"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
